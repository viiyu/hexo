title: 一次Hadoop程序bug排查
date: 2016-04-03 15:33:43
categories: Practice
tags: [hadoop, debug]
---

### 背景
我有一个非常简单的MR程序，会定时跑在团队的hadoop集群上。其主要功能，就是从数据源读取数据，然后写到我们的消息队列里去。

但是在一次项目升级过程中，我们发现这个程序在跑某一份数据的时候，MR job出现了卡住的情况，会在Map阶段一直停在66%。

<!-- more -->

### 过程
我当时写这个程序的时候也是个hadoop新手，只用了counter，和reduce阶段的文本输出，并没有考虑完备的log形式。由于任务是卡在Map阶段，因此，我最终设置的reduce阶段时的文本输出基本失效。在排查过程中主要依赖的是我设置的三个counter，一个为读counter，一个为写counter，还有一个过程counter，用以记录目前程序走到了哪一步。

第一步是根据程序过程counter自查代码，发现程序的hang住位置在所有初始化之后和读取数据之前（`这里的查证步骤已经是重大错误`，后面会详细说明原因）。但是这里的代码仔细阅读后并没有问题。

然后求证hadoop运维同学，去服务器上看log，被告知我的job心跳丢失，服务器端一直尝试重连。但是这些信息依然无法协助排查，直到不久后运维同学给我发来了如下信息：

```
nanosleep({0, 100000000}, NULL)         = 0
epoll_ctl(4, EPOLL_CTL_MOD, 11, {EPOLLIN|EPOLLOUT, {u32=21954144, u64=21954144}}) = 0
futex(0x14effb8, FUTEX_WAKE_PRIVATE, 1) = 1
futex(0x14d9b64, FUTEX_WAIT_PRIVATE, 2767, NULL) = 0
futex(0x14d9b38, FUTEX_WAKE_PRIVATE, 1) = 0
nanosleep({0, 100000000}, ^C <unfinished ...>
```

这是一段我程序的trace信息，可以看出在某个请求连接的地方，程序一直在sleep。这样以来就极大的缩小了范围，程序hang在了数据交互的位置，即从数据源读取或者写入消息队列这两步之一。同时，这里也证明了我一开始使用counter自查是错误的方向（后续会详细说明错误原因）。

但是通过这段信息依然无法进一步定位。因此请教了hadoop运维同学是如何拿到这个信息，他通过直接到job执行机器去strace我的程序，就能拿到这个信息。那既然如此，也同样可以用pstack去拿进程堆栈！！！拿到堆栈后问题就一清二楚了，程序hang在了往消息队列写入的地方。拿着trace和stack信息去找消息队列维护同学，被告知这是以前消息队列客户端的一个bug，在新版本中已经被修复了，升级即可解决问题。

### 结论
1. 在hadoop mr job中，counter是不准确的。
    * 这种知识点需要多钻研才能掌握，《Hadoop 权威指南》（第二版）P227，第二段最后一行，明确指出：“仅当一个作业执行成功之后，计数器的值才是完整可靠的”。
1. 要善于使用pstack和strace工具。
    * mr job本身也就是一个程序，只是其中框架做了一部分工作，因此大部分本地调试技巧其实都是可以应用在mr job上的，方法也很简单：去相应的job执行机器（在hadoop job页面里可以找到执行机器），`ps`命令可以找到相应的job，然后就可以用pstack和strace去查了。
    * 这点若不是hadoop运维教我，我大概不会想到。同时这些工具平常用的也不怎么熟练，还是需要多学习。
